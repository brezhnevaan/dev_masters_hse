import numpy as np
import requests
from datetime import datetime, timezone, timedelta
from sklearn.linear_model import LinearRegression
from multiprocess.pool import Pool
import pandas as pd

# –î–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–µ–∑–æ–Ω–∞ –¥–∞—Ç—ã, –¥–ª—è –∫–æ—Ç–æ—Ä–æ–π –¥–µ–ª–∞–µ–º –∑–∞–ø—Ä–æ—Å –ø–æ API
month_to_season = {12: "winter", 1: "winter", 2: "winter",
                   3: "spring", 4: "spring", 5: "spring",
                   6: "summer", 7: "summer", 8: "summer",
                   9: "autumn", 10: "autumn", 11: "autumn"}

# –°–ª–æ–≤–∞—Ä—å —Å –∏–∫–æ–Ω–∫–∞–º–∏ –¥–ª—è –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø–æ–≥–æ–¥–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π
weather_icons = {
    "Clear": "‚òÄÔ∏è",
    "Rain": "üåßÔ∏è",
    "Snow": "‚ùÑÔ∏è",
    "Clouds": "‚òÅÔ∏è"}

# –ì–ª–∞–≤–Ω–∞—è "—Ç—è–∂–µ–ª–∞—è" —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ –≤—Å–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –≥–æ—Ä–æ–¥—É
def city_statistics(df, window_days=30):
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π –ø–æ —Å–∫–æ–ª—å–∑—è—â–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞–º
    df["rolling_mean"] = df.temperature.rolling(window=window_days).mean()
    df["rolling_std"] = df.temperature.rolling(window=window_days).std()

    df["is_anomaly"] = np.where(
        df["rolling_mean"].notna() & df["rolling_std"].notna(),
        (df["temperature"] < df["rolling_mean"] - 2 * df["rolling_std"]) |
        (df["temperature"] > df["rolling_mean"] + 2 * df["rolling_std"]),
        np.nan
    )

    # –û–±—â–∏–π –ø—Ä–æ—Ñ–∏–ª—å –≥–æ—Ä–æ–¥–∞
    city_profile = df.groupby("city", as_index=False) \
        .agg(temp_mean=("temperature", "mean"),
             temp_min=("temperature", "min"),
             temp_max=("temperature", "max"),
             anomalies_count=("is_anomaly", "sum"),
             obs_count=("timestamp", "size")
             )

    city_profile["anomalies_share"] = city_profile.anomalies_count / city_profile.obs_count

    # + –¢—Ä–µ–Ω–¥
    df_temp = df.copy()
    df_temp["timestamp_unix"] = df_temp["timestamp"].astype("int64") // 10 ** 9

    X = df_temp["timestamp_unix"].values.reshape(-1, 1)
    y = df_temp["temperature"].values

    model = LinearRegression()
    model.fit(X, y)

    df["trend"] = model.predict(X)
    slope = model.coef_[0]

    if abs(slope) < 1e-9:
        trend = "doesn`t exist"
    elif slope < 0:
        trend = "negative"
    else:
        trend = "positive"

    city_profile["trend"] = trend

    # –ü—Ä–æ—Ñ–∏–ª—å —Å–µ–∑–æ–Ω–∞
    # –û—Å—Ç–∞–≤–ª—è–µ–º –≥–æ—Ä–æ–¥ –≤ groupby, —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤—ã–≤–æ–¥—ã —Ñ—É–Ω–∫—Ü–∏–∏ –≤ –æ–¥–∏–Ω df
    season_profile = df.groupby(["season", "city"], as_index=False).agg(
        temp_mean=("temperature", "mean"),
        temp_std=("temperature", "std")
    )

    return df, city_profile, season_profile

# –†–∞—Å–ø–∞—Ä–∞–ª–ª–µ–ª–∏–≤–∞–Ω–∏–µ –≥–ª–∞–≤–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–æ—Ä–æ–¥–æ–≤
def parallel_city_statistics(df, num_processes=8):
    groups_by_city = [df[df["city"] == city].copy().reset_index(drop=True) for city in df["city"].unique()]

    with Pool(processes=num_processes) as pool:
        results = pool.map(city_statistics, groups_by_city)

    df_result = pd.concat([result[0] for result in results], ignore_index=True)
    city_profile_result = pd.concat([result[1] for result in results], ignore_index=True)
    season_profile_result = pd.concat([result[2] for result in results], ignore_index=True)

    return df_result, city_profile_result, season_profile_result

# –°–µ–∑–æ–Ω –¥–ª—è –¥–∞—Ç—ã –∑–∞–ø—Ä–æ—Å–∞ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –ø–æ API
def get_season(unix_timestamp, timezone_offset):
    local_timezone = timezone(timedelta(seconds=timezone_offset))
    local_time = datetime.fromtimestamp(unix_timestamp, tz=local_timezone)
    month = local_time.month
    season = month_to_season[month]

    return season

# –§—É–Ω–∫—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ –≤ API
# –ó–∞–ø—Ä–æ—Å –¥–µ–ª–∞–µ–º –¥–ª—è –æ–¥–Ω–æ–≥–æ –≥–æ—Ä–æ–¥–∞, –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ—Å—Ç—å
def get_response(city, key):
    url = f"https://api.openweathermap.org/data/2.5/weather?q={city}&appid={key}&units=metric"
    try:
        response = requests.get(url)
        response.raise_for_status()

        try:
            data = response.json()
        except ValueError:
            return {"error": "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç API"}

        if (
                "main" not in data or
                "temp" not in data["main"] or
                "dt" not in data or
                "timezone" not in data or
                "weather" not in data or
                "main" not in data["weather"][0]
        ):
            return {"error": "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö –æ—Ç API"}

        temperature = data["main"]["temp"]
        unix_timestamp = data["dt"]
        timezone = data["timezone"]
        season = get_season(unix_timestamp, timezone)
        weather = data["weather"][0]["main"]
        weather_icon = weather_icons.get(weather, "")

        return {"temperature": temperature, "season": season, "weather_icon": weather_icon}

    except requests.exceptions.HTTPError as e:
        if response.status_code == 401:
            return {"error": "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π API-–∫–ª—é—á"}
        elif response.status_code == 404:
            return {"error": "–ì–æ—Ä–æ–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω"}
        else:
            return {"error": f"HTTP –æ—à–∏–±–∫–∞: {e}"}

    except Exception as e:
        return {"error": f"–û—à–∏–±–∫–∞: {e}"}

# –Ø–≤–ª—è–µ—Ç—Å—è –ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª—å–Ω—ã–º –¥–ª—è —Å–µ–∑–æ–Ω–∞
def is_anomaly(city, season, current_temp, season_profile):
    city_season_profile = season_profile[
        (season_profile["city"] == city) & (season_profile["season"] == season)] \
        .copy().reset_index(drop=True)

    if city_season_profile.empty:
        raise ValueError(f"–î–∞–Ω–Ω—ã–µ {city}-{season} –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")

    mean = city_season_profile["temp_mean"].values[0]
    std = city_season_profile["temp_std"].values[0]

    return bool(current_temp < mean - 2 * std or current_temp > mean + 2 * std)